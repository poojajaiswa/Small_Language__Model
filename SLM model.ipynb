{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFmbEk30vgWm",
    "outputId": "6d4d195c-4666-4f23-a401-1bf4590f6891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ashis\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\ashis\\anaconda3\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\ashis\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\ashis\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ashis\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\n",
      "ERROR: No matching distribution found for faiss\n"
     ]
    }
   ],
   "source": [
    "pip install pandas transformers datasets torch scikit-learn faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DQR1c_fSwJb2"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"SLM_Model_dataset.csv\")  # Replace with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "7zQHUYAbwMz4",
    "outputId": "ca233843-41a5-466f-aa49-6e7ef33cdc04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company Name for Emails</th>\n",
       "      <th>Email</th>\n",
       "      <th>Email Status</th>\n",
       "      <th>First Phone</th>\n",
       "      <th>Person Linkedin Url</th>\n",
       "      <th>Website</th>\n",
       "      <th>Company Linkedin Url</th>\n",
       "      <th>...</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Company Address</th>\n",
       "      <th>Company City</th>\n",
       "      <th>Company State</th>\n",
       "      <th>Company Country</th>\n",
       "      <th>Technologies</th>\n",
       "      <th>Apollo Contact Id</th>\n",
       "      <th>Apollo Account Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ray</td>\n",
       "      <td>Pugsley</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Potomac River Running Store</td>\n",
       "      <td>ray@potomacriverrunning.com</td>\n",
       "      <td>Verified</td>\n",
       "      <td>+1 703-798-1582</td>\n",
       "      <td>http://www.linkedin.com/in/ray-pugsley-3a92845</td>\n",
       "      <td>http://www.potomacriverrunning.com</td>\n",
       "      <td>http://www.linkedin.com/company/potomac-river-...</td>\n",
       "      <td>...</td>\n",
       "      <td>Reston</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>United States</td>\n",
       "      <td>11911 Democracy Drive, Reston, Virginia, Unite...</td>\n",
       "      <td>Reston</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>United States</td>\n",
       "      <td>WP Engine, Shopify Product Reviews, Typeform, ...</td>\n",
       "      <td>6499959b8d062a000122f6f3</td>\n",
       "      <td>6499959c8d062a000122f907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen</td>\n",
       "      <td>Froelicher</td>\n",
       "      <td>CEO</td>\n",
       "      <td>WEBWARRIOR</td>\n",
       "      <td>stephenf@webwarrior.com</td>\n",
       "      <td>Verified</td>\n",
       "      <td>+1 407-877-8177</td>\n",
       "      <td>http://www.linkedin.com/in/stephen-froelicher-...</td>\n",
       "      <td>http://www.webwarrior.com</td>\n",
       "      <td>http://www.linkedin.com/company/web-warrior-inc.</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter Garden</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States</td>\n",
       "      <td>67 S Dillard St, Winter Garden, Florida, Unite...</td>\n",
       "      <td>Winter Garden</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States</td>\n",
       "      <td>Outlook, Microsoft Office 365, Google Tag Mana...</td>\n",
       "      <td>649995edb0728d000164df7b</td>\n",
       "      <td>649995efb0728d000164e211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ian</td>\n",
       "      <td>Cartwright</td>\n",
       "      <td>Chief Executive Officer</td>\n",
       "      <td>mahabis</td>\n",
       "      <td>ianc@mahabis.com</td>\n",
       "      <td>Verified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.linkedin.com/in/ian-cartwright</td>\n",
       "      <td>http://www.mahabis.com</td>\n",
       "      <td>http://www.linkedin.com/company/mahabis</td>\n",
       "      <td>...</td>\n",
       "      <td>Saint Albans</td>\n",
       "      <td>England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>27 Arthur Road, London, England, United Kingdo...</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Route 53, Mailchimp Mandrill, Rackspace MailGu...</td>\n",
       "      <td>649a96f3f845b30001de430b</td>\n",
       "      <td>649a96f3f845b30001de432c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Betty</td>\n",
       "      <td>Tung</td>\n",
       "      <td>Founder and CEO</td>\n",
       "      <td>FERA</td>\n",
       "      <td>betty@ifera.com</td>\n",
       "      <td>Verified</td>\n",
       "      <td>+1 310-370-8538</td>\n",
       "      <td>http://www.linkedin.com/in/betty-tung-813835b</td>\n",
       "      <td>http://www.ferastyle.com</td>\n",
       "      <td>http://www.linkedin.com/company/ferastyle</td>\n",
       "      <td>...</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>3521 Challenger St, Torrance, California, Unit...</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>Gmail, Google Apps, Shopify, Facebook Login (C...</td>\n",
       "      <td>649a97702563ed000184ad60</td>\n",
       "      <td>649a96dac0a62b00010b939c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debra</td>\n",
       "      <td>Saavedra</td>\n",
       "      <td>Co-Founder</td>\n",
       "      <td>Saavy Naturals</td>\n",
       "      <td>debra@saavynaturals.com</td>\n",
       "      <td>Verified</td>\n",
       "      <td>+1 646-481-9671</td>\n",
       "      <td>http://www.linkedin.com/in/debrasaavedra</td>\n",
       "      <td>http://www.saavynaturals.com</td>\n",
       "      <td>http://www.linkedin.com/company/saavy</td>\n",
       "      <td>...</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>20338 Corisco St, Los Angeles, California, Uni...</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>Outlook, Microsoft Office 365, Shopify, Shopif...</td>\n",
       "      <td>649a97a2e7682c00015aa67b</td>\n",
       "      <td>649a970b34921900013e3ce2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name   Last Name                    Title  \\\n",
       "0        Ray     Pugsley                    Owner   \n",
       "1    Stephen  Froelicher                      CEO   \n",
       "2        Ian  Cartwright  Chief Executive Officer   \n",
       "3      Betty        Tung          Founder and CEO   \n",
       "4      Debra    Saavedra               Co-Founder   \n",
       "\n",
       "       Company Name for Emails                        Email Email Status  \\\n",
       "0  Potomac River Running Store  ray@potomacriverrunning.com     Verified   \n",
       "1                   WEBWARRIOR      stephenf@webwarrior.com     Verified   \n",
       "2                      mahabis             ianc@mahabis.com     Verified   \n",
       "3                         FERA              betty@ifera.com     Verified   \n",
       "4               Saavy Naturals      debra@saavynaturals.com     Verified   \n",
       "\n",
       "       First Phone                                Person Linkedin Url  \\\n",
       "0  +1 703-798-1582     http://www.linkedin.com/in/ray-pugsley-3a92845   \n",
       "1  +1 407-877-8177  http://www.linkedin.com/in/stephen-froelicher-...   \n",
       "2              NaN          http://www.linkedin.com/in/ian-cartwright   \n",
       "3  +1 310-370-8538      http://www.linkedin.com/in/betty-tung-813835b   \n",
       "4  +1 646-481-9671           http://www.linkedin.com/in/debrasaavedra   \n",
       "\n",
       "                              Website  \\\n",
       "0  http://www.potomacriverrunning.com   \n",
       "1           http://www.webwarrior.com   \n",
       "2              http://www.mahabis.com   \n",
       "3            http://www.ferastyle.com   \n",
       "4        http://www.saavynaturals.com   \n",
       "\n",
       "                                Company Linkedin Url  ...           City  \\\n",
       "0  http://www.linkedin.com/company/potomac-river-...  ...         Reston   \n",
       "1   http://www.linkedin.com/company/web-warrior-inc.  ...  Winter Garden   \n",
       "2            http://www.linkedin.com/company/mahabis  ...   Saint Albans   \n",
       "3          http://www.linkedin.com/company/ferastyle  ...       Torrance   \n",
       "4              http://www.linkedin.com/company/saavy  ...    Los Angeles   \n",
       "\n",
       "        State         Country  \\\n",
       "0    Virginia   United States   \n",
       "1     Florida   United States   \n",
       "2     England  United Kingdom   \n",
       "3  California   United States   \n",
       "4  California   United States   \n",
       "\n",
       "                                     Company Address   Company City  \\\n",
       "0  11911 Democracy Drive, Reston, Virginia, Unite...         Reston   \n",
       "1  67 S Dillard St, Winter Garden, Florida, Unite...  Winter Garden   \n",
       "2  27 Arthur Road, London, England, United Kingdo...         London   \n",
       "3  3521 Challenger St, Torrance, California, Unit...       Torrance   \n",
       "4  20338 Corisco St, Los Angeles, California, Uni...    Los Angeles   \n",
       "\n",
       "  Company State Company Country  \\\n",
       "0      Virginia   United States   \n",
       "1       Florida   United States   \n",
       "2       England  United Kingdom   \n",
       "3    California   United States   \n",
       "4    California   United States   \n",
       "\n",
       "                                        Technologies  \\\n",
       "0  WP Engine, Shopify Product Reviews, Typeform, ...   \n",
       "1  Outlook, Microsoft Office 365, Google Tag Mana...   \n",
       "2  Route 53, Mailchimp Mandrill, Rackspace MailGu...   \n",
       "3  Gmail, Google Apps, Shopify, Facebook Login (C...   \n",
       "4  Outlook, Microsoft Office 365, Shopify, Shopif...   \n",
       "\n",
       "          Apollo Contact Id         Apollo Account Id  \n",
       "0  6499959b8d062a000122f6f3  6499959c8d062a000122f907  \n",
       "1  649995edb0728d000164df7b  649995efb0728d000164e211  \n",
       "2  649a96f3f845b30001de430b  649a96f3f845b30001de432c  \n",
       "3  649a97702563ed000184ad60  649a96dac0a62b00010b939c  \n",
       "4  649a97a2e7682c00015aa67b  649a970b34921900013e3ce2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u8YGLMn4wPes"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "df = df[['Email', 'Company Name for Emails', 'Industry', 'Technologies', 'Website']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sDs-rpfpwI2y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tQ7wqM6wSww",
    "outputId": "84c1a7b4-ac41-4922-ff66-3261e5acfee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Email  Company Name for Emails  \\\n",
      "331  natalie@nataliemariejewellery.com  Natalie Marie Jewellery   \n",
      "143              dennis@theundress.com              The Undress   \n",
      "440             bianca@biancamilov.com     Bianca Milov Designs   \n",
      "423             cassie@barbarakatz.com             Barbara Katz   \n",
      "497                    dina@kidpik.com                   kidpik   \n",
      "\n",
      "                   Industry  \\\n",
      "331                  retail   \n",
      "143       apparel & fashion   \n",
      "440  luxury goods & jewelry   \n",
      "423                  retail   \n",
      "497       apparel & fashion   \n",
      "\n",
      "                                          Technologies  \\\n",
      "331  Klaviyo, Outlook, Microsoft Office 365, Shopif...   \n",
      "143  Gmail, Google Apps, Zendesk, Shopify, VueJS, A...   \n",
      "440  Outlook, Mobile Friendly, Shopify, Bootstrap F...   \n",
      "423  Outlook, Shopify Product Reviews, UPS, Google ...   \n",
      "497  Cloudflare DNS, Sendgrid, Outlook, Zendesk, Cl...   \n",
      "\n",
      "                                  Website  \n",
      "331  http://www.nataliemariejewellery.com  \n",
      "143             http://www.theundress.com  \n",
      "440            http://www.biancamilov.com  \n",
      "423            http://www.barbarakatz.com  \n",
      "497                 http://www.kidpik.com  \n"
     ]
    }
   ],
   "source": [
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_data.head())  # Check sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogMFPPlfwVOm",
    "outputId": "3f66684c-734c-4925-ff74-4f141e29bfe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ashis\\anaconda3\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYEXCzs3wYBk",
    "outputId": "0b139977-2082-453b-8f2b-6bd7093dc930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1+cu121\n",
      "Uninstalling torch-2.5.1+cu121:\n",
      "  Successfully uninstalled torch-2.5.1+cu121\n",
      "Found existing installation: torchvision 0.20.1+cu121\n",
      "Uninstalling torchvision-0.20.1+cu121:\n",
      "  Successfully uninstalled torchvision-0.20.1+cu121\n",
      "Found existing installation: torchaudio 2.5.1+cu121\n",
      "Uninstalling torchaudio-2.5.1+cu121:\n",
      "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Files removed: 20\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/203.0 MB 9.0 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 6.8/203.0 MB 17.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 9.7/203.0 MB 15.5 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 13.6/203.0 MB 18.6 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 19.4/203.0 MB 20.4 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 21.5/203.0 MB 18.4 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 23.6/203.0 MB 16.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 24.6/203.0 MB 15.1 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 27.8/203.0 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 29.1/203.0 MB 14.2 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 29.9/203.0 MB 13.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 32.2/203.0 MB 13.6 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 34.1/203.0 MB 12.7 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 35.7/203.0 MB 12.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 38.0/203.0 MB 12.3 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 39.8/203.0 MB 12.2 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 41.7/203.0 MB 12.0 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 43.8/203.0 MB 11.9 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 45.6/203.0 MB 11.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 47.4/203.0 MB 11.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 49.3/203.0 MB 11.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 51.1/203.0 MB 11.3 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 53.2/203.0 MB 11.3 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 55.1/203.0 MB 11.2 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 57.1/203.0 MB 11.1 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 59.0/203.0 MB 11.1 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 61.1/203.0 MB 11.0 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 62.4/203.0 MB 10.9 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 65.8/203.0 MB 11.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 68.4/203.0 MB 11.2 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 72.1/203.0 MB 11.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 75.8/203.0 MB 11.5 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 77.6/203.0 MB 11.5 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 83.4/203.0 MB 12.0 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 88.1/203.0 MB 12.3 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 90.4/203.0 MB 12.4 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 93.1/203.0 MB 12.4 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 94.9/203.0 MB 12.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 96.2/203.0 MB 12.0 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 99.4/203.0 MB 12.1 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 101.7/203.0 MB 12.1 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 103.0/203.0 MB 12.0 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 105.1/203.0 MB 11.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 107.5/203.0 MB 11.9 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 109.8/203.0 MB 11.9 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 112.2/203.0 MB 11.9 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 114.6/203.0 MB 11.9 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 116.9/203.0 MB 11.9 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 119.3/203.0 MB 11.8 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 121.4/203.0 MB 11.8 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 123.7/203.0 MB 11.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 125.8/203.0 MB 11.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 128.2/203.0 MB 11.8 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 130.5/203.0 MB 11.8 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 133.4/203.0 MB 11.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 135.8/203.0 MB 11.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 137.6/203.0 MB 11.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 139.2/203.0 MB 11.7 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 142.1/203.0 MB 11.7 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 144.2/203.0 MB 11.7 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 147.1/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 149.2/203.0 MB 11.8 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 152.3/203.0 MB 11.8 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 154.7/203.0 MB 11.8 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 159.4/203.0 MB 11.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 161.2/203.0 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 163.6/203.0 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 165.9/203.0 MB 11.7 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 168.0/203.0 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 169.9/203.0 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 172.0/203.0 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 174.1/203.0 MB 11.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 174.1/203.0 MB 11.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 174.6/203.0 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 175.1/203.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 178.8/203.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 179.8/203.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 182.5/203.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.5/203.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.6/203.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 188.2/203.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 191.1/203.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 193.2/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.3/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.4/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.5/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.3/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.0/203.0 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 86.7 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 11.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip cache purge\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\ashis\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ashis\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ashis\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "F2F6c-0ewbkT"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kwy7kbntxJS0",
    "outputId": "bad13df0-ad33-44ec-ce2b-455bbc205575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Check if GPU is detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\ashis\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ashis\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ashis\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8E1yZtx5xQEz",
    "outputId": "b7ecee7d-cd81-4c37-c67b-26ebcda58350",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Define the model name\n",
    "MODEL = \"distilbert-base-uncased\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WPx401TxVhy",
    "outputId": "8bd70200-21a6-4e7f-9d56-84fb5bc3bec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.is_torch_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZu5c8o1yBL8",
    "outputId": "ec18bd34-e956-496d-cd95-4595c160ac6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ashis\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KCJnSlOYyDqY"
   },
   "outputs": [],
   "source": [
    "# python -c 'from transformers import AutoModel'\n",
    "\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7G4Zo4SEyHoS"
   },
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6ui0ZaByKbQ",
    "outputId": "22fb24ab-36c1-4f62-ec05-e749fd66661f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Email  \\\n",
      "0  ray@potomacriverrunning.com   \n",
      "1      stephenf@webwarrior.com   \n",
      "2             ianc@mahabis.com   \n",
      "3              betty@ifera.com   \n",
      "4      debra@saavynaturals.com   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [[0.15350045, -0.32611102, 0.08533678, 0.07328...  \n",
      "1  [[0.2799484, -0.044264235, 0.11270272, -0.0416...  \n",
      "2  [[0.317852, -0.048168078, -0.0009629925, -0.14...  \n",
      "3  [[0.27171758, -0.12644844, 0.039165154, 0.0003...  \n",
      "4  [[0.124756545, -0.11763144, 0.096595004, 0.063...  \n"
     ]
    }
   ],
   "source": [
    "# Convert email subjects into embeddings\n",
    "df['Embeddings'] = df['Email'].apply(lambda x: get_embedding(str(x)))\n",
    "\n",
    "print(df[['Email', 'Embeddings']].head())  # Check results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1Q8jVIPyMoJ",
    "outputId": "d69b356c-7ce1-467a-c07f-4acab4e0aa10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: faiss-cpu 1.9.0.post1\n",
      "Uninstalling faiss-cpu-1.9.0.post1:\n",
      "  Successfully uninstalled faiss-cpu-1.9.0.post1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping faiss as it is not installed.\n",
      "WARNING: Skipping faiss-gpu as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 20\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp312-cp312-win_amd64.whl (13.8 MB)\n",
      "   ---------------------------------------- 0.0/13.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.8 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.7/13.8 MB 16.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.2/13.8 MB 19.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.6/13.8 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.8/13.8 MB 18.5 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall faiss faiss-cpu faiss-gpu -y\n",
    "!pip cache purge\n",
    "!pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zByp8299y2W8"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Jl9hrpZ_yTs3"
   },
   "outputs": [],
   "source": [
    "# Convert embeddings to numpy array\n",
    "embeddings_array = np.array(df['Embeddings'].tolist()).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idHSxtBQznnQ",
    "outputId": "0d29383b-eeda-4d2f-ab1b-0e623d2725cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(\"FAISS version:\", faiss.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XZ_rFvOyT2S",
    "outputId": "f0f04bdd-58ca-4c75-c890-f3ced906497f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example: Create random embeddings (100 vectors, each with 768 dimensions)\n",
    "embeddings_array = np.random.rand(100, 768).astype('float32')  # Must be (N, D)\n",
    "\n",
    "# Create FAISS index (768-dimensional embeddings)\n",
    "index = faiss.IndexFlatL2(768)\n",
    "\n",
    "# Add embeddings to FAISS\n",
    "index.add(embeddings_array)\n",
    "\n",
    "print(\"FAISS index created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Av4Y0d8SzTZQ"
   },
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "faiss.write_index(index, \"threat_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQNdwk-t0ZJf",
    "outputId": "2d592e41-b330-4abd-d971-aee420607b29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Email                Industry  \\\n",
      "94  fran@georgehowellcoffee.com                  retail   \n",
      "18        matthew@watchgang.com  luxury goods & jewelry   \n",
      "56     steve@meghanfabulous.com       apparel & fashion   \n",
      "63            brad@reneruiz.net       apparel & fashion   \n",
      "59     michelle@priveporter.com                  retail   \n",
      "\n",
      "                                         Technologies  \n",
      "94  Outlook, MailChimp SPF, Microsoft Office 365, ...  \n",
      "18  Cloudflare DNS, Mailchimp Mandrill, Gmail, Goo...  \n",
      "56  Gmail, Google Apps, Sendgrid, Amazon AWS, Goog...  \n",
      "63  Outlook, Amazon AWS, Gmail, Google Apps, Wix, ...  \n",
      "59  Rackspace Email, Shopify, reCAPTCHA, Typekit, ...  \n"
     ]
    }
   ],
   "source": [
    "def recommend_threats(query_email):\n",
    "    query_embedding = get_embedding(query_email).astype('float32')\n",
    "    # Reshape query_embedding to have shape (1, embedding_dim)\n",
    "    query_embedding = query_embedding.reshape(1, -1)\n",
    "    _, similar_threats = index.search(query_embedding, 5)  # Get top 5 recommendations\n",
    "    return df.iloc[similar_threats[0]]\n",
    "# Example query\n",
    "query_email = \"Urgent: Your bank account is locked. Click here to verify.\"\n",
    "recommended_threats = recommend_threats(query_email)\n",
    "\n",
    "print(recommended_threats[['Email', 'Industry', 'Technologies']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIXXmz3M0y2R",
    "outputId": "83dc1bb9-607b-479c-b89c-19eb633d59fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\ashis\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4vsDRQMo5aLs"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "\n",
    "# Convert Pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_data[['Email', 'Industry']])\n",
    "test_dataset = Dataset.from_pandas(test_data[['Email', 'Industry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "sijaNPrF0r4O"
   },
   "outputs": [],
   "source": [
    "# # Convert Pandas DataFrame to Hugging Face Dataset\n",
    "# train_dataset = Dataset.from_pandas(train_data[['Email', 'Industry']])\n",
    "# test_dataset = Dataset.from_pandas(test_data[['Email', 'Industry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRSCNdjF08c9",
    "outputId": "6fc47668-0ed9-432b-8952-d6d195067e09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\ashis\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\ashis\\anaconda3\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers[torch]\n",
    "!pip install -U transformers[torch] accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAYFRFs40-Ns",
    "outputId": "79838a42-f823-4d6c-8cf5-0631b92e13a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ebCCfX7C5ux9"
   },
   "outputs": [],
   "source": [
    "# # Preprocessing function\n",
    "# def preprocess_function(examples):\n",
    "#     # Tokenize the email text\n",
    "#     # return type has to be dictionary and the keys should be input_ids, attention_mask, and labels\n",
    "#     # print('examples', examples)\n",
    "#     tokenized_inputs = tokenizer(examples['Email'], padding='max_length', truncation=True)\n",
    "#     # add labels (assuming 'Industry' column contains labels)\n",
    "#     tokenized_inputs['labels'] = examples['Industry']\n",
    "#     return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7YT1fTEm52ND"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Apply preprocessing to the datasets\n",
    "# train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "# test_dataset = test_dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "076690824db747cebd9cd219bff7e9fe",
      "2acf27316c124cf2af61e6c9f81520bb",
      "470eedbf8bc54622a65839aace04bb8c",
      "9adfab1073984e1fb193336b3a30249a",
      "0ebc3afefd0e48bdaf488119296d9673",
      "6cd81586b2564f6db43722c0a2e8d990",
      "7f11124dfd4846789bb35ae408138438",
      "2c94bf8462bd4d0bb434469b0817c912",
      "7a76a06aaf54471eabafc7c566ad2ea3",
      "276a96fe2820470b8a556739c61ec16d",
      "b4d91e3543ea440aa2478fa0768ac415",
      "ffdb8d2acc5746d081a35d2cb851152f",
      "dfae20027c30474ba30692bd7f8a0afa",
      "d2a8a51646a44a5aa3369c6c17f2806a",
      "46abebd7865f4928b853c6e7168236e9",
      "b553a9010e0148d7b5a3f96c0dd2b4ab",
      "d8d4f2fbfd184dd5b5dd6bda37fd9297",
      "9ada43504d9c4f13b5812ba1c67f71a0",
      "7b5699413f404ddca3d09fcfe2628c9e",
      "6fb0c8f8001b4574841adb36d5ad06d8",
      "8c1b78f1464c4d71a4bd6c2452e4971f",
      "8b241554d278445685bbc7361cb61019"
     ]
    },
    "id": "VeUO1zqM6n11",
    "outputId": "a2d8ad8b-8873-4840-baf1-d8f3e713fe90"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff79c9465b2491f9c4777c6d13321e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfa3b1bdd04413fbf550491d702e3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a label mapping dictionary\n",
    "industry_labels = train_data['Industry'].unique().tolist()  # Convert to list\n",
    "\n",
    "# Add any missing labels from test data\n",
    "for industry in test_data['Industry'].unique():\n",
    "    if industry not in industry_labels:\n",
    "        industry_labels.append(industry)\n",
    "\n",
    "label_map = {label: idx for idx, label in enumerate(industry_labels)}\n",
    "\n",
    "# Update the preprocess_function to use numerical labels\n",
    "def preprocess_function(examples):\n",
    "    tokenized_inputs = tokenizer(examples['Email'], padding='max_length', truncation=True)\n",
    "    # Convert 'Industry' to numerical labels using the label_map\n",
    "    tokenized_inputs['labels'] = [label_map.get(industry, -1) for industry in examples['Industry']] # Handle missing labels with -1\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply preprocessing to the datasets (using the updated preprocess_function)\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13ACLSKr6-wg",
    "outputId": "1689f9b8-c112-4e19-bb74-75a3f3bd8eb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "# Get the number of unique industry labels\n",
    "num_labels = len(train_data['Industry'].unique())\n",
    "\n",
    "# Load the model with the correct number of labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "baVv9hNu1Ac_"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # This line was already in your imports\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "# ... (Your other imports and code) ...\n",
    "\n",
    "# Load dataset (make sure you have the correct file path)\n",
    "df = pd.read_csv(\"SLM_Model_dataset.csv\")\n",
    "\n",
    "# ... (Your data preprocessing steps) ...\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42) # Changed this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vp7ozYL38GLR",
    "outputId": "d35da91b-e651-4cbb-fd22-ab20b5f59b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from fastapi) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from fastapi) (4.11.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from starlette<0.46.0,>=0.40.0->fastapi) (4.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: uvicorn, starlette, fastapi\n",
      "Successfully installed fastapi-0.115.7 starlette-0.45.3 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "q26tXEOk1CsX"
   },
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/recommend/{query_email}\")\n",
    "def recommend(query_email: str):\n",
    "    return recommend_threats(query_email).to_dict()\n",
    "\n",
    "# Remove if __name__ == \"__main__\": block\n",
    "# Instead, start the server using `uvicorn.run` from a terminal:\n",
    "# uvicorn main:app --reload --host 0.0.0.0 --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "EV_nLfti-mtM"
   },
   "outputs": [],
   "source": [
    "# Create X_test and y_test\n",
    "# Assuming 'Email' is the input feature and 'Industry' is the target variable\n",
    "X_test = test_data['Email']\n",
    "y_test = test_data['Industry']\n",
    "\n",
    "# Tokenize the input data for prediction\n",
    "# You may need to preprocess your X_test data in the same way you did for training\n",
    "# using the `tokenizer` you have defined earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "CV1YfFUT-9t2"
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer (make sure you have the correct model name)\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer # Import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") # Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "AMc0WSFu-pmv"
   },
   "outputs": [],
   "source": [
    "# Example preprocessing:\n",
    "tokenized_inputs = tokenizer(\n",
    "    list(X_test), padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "# NOTE: `model.predict()` is not directly available for Hugging Face models.\n",
    "# You need to use `model()` for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "TFro-Hp4B2Ub"
   },
   "outputs": [],
   "source": [
    "# Update the preprocess_function to convert labels to integers if they are strings\n",
    "def preprocess_function(examples):\n",
    "    tokenized_inputs = tokenizer(examples['Email'], padding='max_length', truncation=True)\n",
    "\n",
    "    # Convert 'Industry' to numerical labels if they are strings\n",
    "    labels = examples['Industry']\n",
    "    if isinstance(labels[0], str):  # Check if labels are strings\n",
    "        unique_labels = list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "GTUqY320DALx"
   },
   "outputs": [],
   "source": [
    "# ipython-input-31-b5693a3e663d\n",
    "# Create a label mapping dictionary if it doesn't exist\n",
    "if 'label_map' not in locals():  # Check if label_map is already defined\n",
    "    industry_labels = train_data['Industry'].unique().tolist()  # Get unique industry labels from train_data\n",
    "\n",
    "    # Add any missing labels from test data\n",
    "    for industry in test_data['Industry'].unique():\n",
    "        if industry not in industry_labels:\n",
    "            industry_labels.append(industry)\n",
    "\n",
    "    label_map = {label: idx for idx, label in enumerate(industry_labels)}\n",
    "\n",
    "# Convert y_test to numerical labels using the label_map\n",
    "y_test_numerical = [label_map.get(industry, -1) for industry in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OdgowMD-puZ",
    "outputId": "28152248-f6c8-4107-b637-41b49003d1d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         2\n",
      "           0       0.31      1.00      0.47        31\n",
      "           1       0.00      0.00      0.00        34\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31       100\n",
      "   macro avg       0.02      0.06      0.03       100\n",
      "weighted avg       0.10      0.31      0.15       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ashis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ashis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ipython-input-20-39093388b1e7\n",
    "# Load necessary libraries and the pre-trained model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "# Load pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2) # Assuming 2 labels for your classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "tokenized_inputs = tokenizer(\n",
    "    list(X_test), padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Assuming your model is `AutoModelForSequenceClassification`, this is how you get the predicted labels:\n",
    "# import torch  # Import torch here (already imported above)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_inputs)\n",
    "    y_pred = torch.argmax(outputs.logits, dim=1).numpy()\n",
    "\n",
    "# Convert y_test to numerical labels if it's not already\n",
    "if isinstance(y_test.iloc[0], str):  # Check if labels are strings\n",
    "    # Create a label mapping dictionary if it doesn't exist\n",
    "    if 'label_map' not in locals():  # Check if label_map is already defined\n",
    "        industry_labels = train_data['Industry'].unique().tolist()  # Get unique industry labels from train_data\n",
    "\n",
    "        # Add any missing labels from test data\n",
    "        for industry in test_data['Industry'].unique():\n",
    "            if industry not in industry_labels:\n",
    "                industry_labels.append(industry)\n",
    "\n",
    "        label_map = {label: idx for idx, label in enumerate(industry_labels)}\n",
    "\n",
    "    # Convert y_test to numerical labels using the label_map\n",
    "    y_test_numerical = [label_map.get(industry, -1) for industry in y_test]\n",
    "else:\n",
    "    y_test_numerical = y_test  # If y_test is already numerical, use it directly\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "# Assuming you have classification_report and y_test defined:\n",
    "# from sklearn.metrics import classification_report # Import classification_report\n",
    "print(classification_report(y_test_numerical, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZykVYa57zeT",
    "outputId": "4c37319f-a431-40b4-f4b7-7cd1fc92b332"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24974478408443490d3a599eaaedc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashis\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0599fec6694a778fb1a762148131a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777c23b9fe2747378c773c0eb4b56292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e2d9176f874fd483d7399bcf7f8d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.25      0.25      0.25         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load model and tokenizer\n",
    "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"  # Use a valid pre-trained or custom model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to make predictions\n",
    "def get_predictions(text_list):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits  # Extract logits\n",
    "    predictions = torch.argmax(logits, dim=1)  # Get predicted class\n",
    "    return predictions.numpy()\n",
    "\n",
    "# Example test data\n",
    "X_test = [\n",
    "    \"Your account is compromised. Click here to reset your password.\",\n",
    "    \"Congratulations! You've won a prize. Claim now.\",\n",
    "    \"Hello, your payment has been processed successfully.\"\n",
    "]\n",
    "\n",
    "y_test = [1, 1, 0]  # Example true labels (1 = phishing, 0 = normal)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = get_predictions(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSd6j46P-oux",
    "outputId": "cfad9976-a144-487d-c54e-8c4b585e1291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load a pre-trained model and tokenizer\n",
    "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"  # Use a valid model or local path if trained\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to make predictions\n",
    "def get_predictions(text_list):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits  # Extract logits\n",
    "    predictions = torch.argmax(logits, dim=1)  # Get predicted class\n",
    "    return predictions.numpy()\n",
    "\n",
    "# Example test data (Phishing Detection)\n",
    "test_emails = [\n",
    "    \"Your account is compromised. Click here to reset your password.\",\n",
    "    \"Congratulations! You've won a prize. Claim now.\",\n",
    "    \"Hello, your payment has been processed successfully.\"\n",
    "]\n",
    "\n",
    "# Get predictions\n",
    "predicted_labels = get_predictions(test_emails)\n",
    "print(\"Predicted Labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "CgiNfCJY9trO"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbmb4Q9mnl4x",
    "outputId": "4bc991b1-2a7a-4dd3-cb5d-351834a342c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.25      0.25      0.25         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert test data into a list of strings\n",
    "X_test = X_test.tolist() if not isinstance(X_test, list) else X_test\n",
    "\n",
    "# Get predictions for test data\n",
    "y_pred = get_predictions(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O04z3yhupd68",
    "outputId": "95e5664b-2db2-4311-c75f-de4c157fef6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    email_text = data.get(\"email\", \"\")\n",
    "    if not email_text:\n",
    "        return jsonify({\"error\": \"No email provided\"}), 400\n",
    "\n",
    "    # Get prediction\n",
    "    prediction = get_predictions([email_text])[0]\n",
    "    return jsonify({\"prediction\": int(prediction)})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=5000, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IohnA7OxphaO",
    "outputId": "a77c060c-0d44-4503-bf71-fdb1fd67c078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Email: Your account is compromised. Click here to reset your password.\n",
      "Predicted Label: Legitimate\n",
      "Confidence Scores: [9.9959213e-01 4.0787805e-04]\n",
      "\n",
      "Email: Congratulations! You've won a prize. Claim now.\n",
      "Predicted Label: Phishing\n",
      "Confidence Scores: [1.6337058e-04 9.9983656e-01]\n",
      "\n",
      "Email: Hello, your payment has been processed successfully.\n",
      "Predicted Label: Phishing\n",
      "Confidence Scores: [5.396717e-04 9.994603e-01]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "MODEL_PATH = \"distilbert-base-uncased-finetuned-sst-2-english\"  # Change this if using a custom trained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to get predictions and confidence scores\n",
    "def get_predictions(text_list):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits  # Extract logits (raw model outputs)\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)  # Convert to probabilities\n",
    "    predictions = torch.argmax(logits, dim=1)  # Get predicted class (0 or 1)\n",
    "\n",
    "    return predictions.numpy(), probabilities.numpy()\n",
    "\n",
    "# Example test emails\n",
    "test_emails = [\n",
    "    \"Your account is compromised. Click here to reset your password.\",  # Likely phishing\n",
    "    \"Congratulations! You've won a prize. Claim now.\",  # Likely phishing\n",
    "    \"Hello, your payment has been processed successfully.\"  # Likely normal\n",
    "]\n",
    "\n",
    "# Get predictions\n",
    "predicted_labels, confidence_scores = get_predictions(test_emails)\n",
    "\n",
    "# Print results\n",
    "for i, email in enumerate(test_emails):\n",
    "    print(f\"\\nEmail: {email}\")\n",
    "    print(f\"Predicted Label: {'Phishing' if predicted_labels[i] == 1 else 'Legitimate'}\")\n",
    "    print(f\"Confidence Scores: {confidence_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9P8GFZHr77a5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "076690824db747cebd9cd219bff7e9fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2acf27316c124cf2af61e6c9f81520bb",
       "IPY_MODEL_470eedbf8bc54622a65839aace04bb8c",
       "IPY_MODEL_9adfab1073984e1fb193336b3a30249a"
      ],
      "layout": "IPY_MODEL_0ebc3afefd0e48bdaf488119296d9673"
     }
    },
    "0ebc3afefd0e48bdaf488119296d9673": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "276a96fe2820470b8a556739c61ec16d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2acf27316c124cf2af61e6c9f81520bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cd81586b2564f6db43722c0a2e8d990",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7f11124dfd4846789bb35ae408138438",
      "value": "Map:â€‡100%"
     }
    },
    "2c94bf8462bd4d0bb434469b0817c912": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46abebd7865f4928b853c6e7168236e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c1b78f1464c4d71a4bd6c2452e4971f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8b241554d278445685bbc7361cb61019",
      "value": "â€‡98/98â€‡[00:00&lt;00:00,â€‡889.90â€‡examples/s]"
     }
    },
    "470eedbf8bc54622a65839aace04bb8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c94bf8462bd4d0bb434469b0817c912",
      "max": 392,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a76a06aaf54471eabafc7c566ad2ea3",
      "value": 392
     }
    },
    "6cd81586b2564f6db43722c0a2e8d990": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb0c8f8001b4574841adb36d5ad06d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a76a06aaf54471eabafc7c566ad2ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b5699413f404ddca3d09fcfe2628c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f11124dfd4846789bb35ae408138438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b241554d278445685bbc7361cb61019": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c1b78f1464c4d71a4bd6c2452e4971f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ada43504d9c4f13b5812ba1c67f71a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9adfab1073984e1fb193336b3a30249a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_276a96fe2820470b8a556739c61ec16d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b4d91e3543ea440aa2478fa0768ac415",
      "value": "â€‡392/392â€‡[00:00&lt;00:00,â€‡720.23â€‡examples/s]"
     }
    },
    "b4d91e3543ea440aa2478fa0768ac415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b553a9010e0148d7b5a3f96c0dd2b4ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2a8a51646a44a5aa3369c6c17f2806a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b5699413f404ddca3d09fcfe2628c9e",
      "max": 98,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6fb0c8f8001b4574841adb36d5ad06d8",
      "value": 98
     }
    },
    "d8d4f2fbfd184dd5b5dd6bda37fd9297": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfae20027c30474ba30692bd7f8a0afa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8d4f2fbfd184dd5b5dd6bda37fd9297",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9ada43504d9c4f13b5812ba1c67f71a0",
      "value": "Map:â€‡100%"
     }
    },
    "ffdb8d2acc5746d081a35d2cb851152f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dfae20027c30474ba30692bd7f8a0afa",
       "IPY_MODEL_d2a8a51646a44a5aa3369c6c17f2806a",
       "IPY_MODEL_46abebd7865f4928b853c6e7168236e9"
      ],
      "layout": "IPY_MODEL_b553a9010e0148d7b5a3f96c0dd2b4ab"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
